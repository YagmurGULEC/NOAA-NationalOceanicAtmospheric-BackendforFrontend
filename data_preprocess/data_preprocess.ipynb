{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting aiofiles\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading numpy-2.2.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, aiofiles, pandas\n",
      "Successfully installed aiofiles-24.1.0 numpy-2.2.4 pandas-2.2.3 pytz-2025.1 tzdata-2025.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas aiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 JSON files found.\n",
      "./api_responses/datasets/datasets_offset_0.json\n",
      "./api_responses/datasets/datasets_offset_10.json\n",
      "{'GHCND': 'Daily Summaries', 'GSOM': 'Global Summary of the Month', 'GSOY': 'Global Summary of the Year', 'NEXRAD2': 'Weather Radar (Level II)', 'NEXRAD3': 'Weather Radar (Level III)', 'NORMAL_ANN': 'Normals Annual/Seasonal', 'NORMAL_DLY': 'Normals Daily', 'NORMAL_HLY': 'Normals Hourly', 'NORMAL_MLY': 'Normals Monthly', 'PRECIP_15': 'Precipitation 15 Minute', 'PRECIP_HLY': 'Precipitation Hourly'}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiofiles\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "semaphore = asyncio.Semaphore(50)\n",
    "async def read_json_file(file):\n",
    "    print (file)\n",
    "    \"\"\"Read JSON files and extract required fields.\"\"\"\n",
    "    async with semaphore:\n",
    "        async with aiofiles.open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            try:\n",
    "                data = json.loads(await f.read())\n",
    "                try:\n",
    "                    return data[\"results\"]\n",
    "\n",
    "                except KeyError:\n",
    "                    print(f\"⚠️ Missing 'results' field in {file}\")\n",
    "                    return None\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"❌ Error parsing {file}\")\n",
    "                return None\n",
    "            \n",
    "async def write_json_file(file, data):\n",
    "    \"\"\"Write JSON files asynchronously.\"\"\"\n",
    "    async with semaphore:\n",
    "        async with aiofiles.open(file, \"w\", encoding=\"utf-8\") as f:\n",
    "            await f.write(json.dumps(data, indent=4, ensure_ascii=False))\n",
    "            print(f\"✅ {file} written.\")\n",
    "            return True\n",
    "\n",
    "DATATYPE=\"TAVG\"\n",
    "DATASET=\"GSOM\"  \n",
    "DATE=\"2023-03-14_2025-03-14\"\n",
    "OUTPUT_FILE_JSON=f\"{DATATYPE}_{DATASET}_{DATE}.json\"\n",
    "OUTPUT_FILE_CSV=f\"{DATATYPE}_{DATASET}_{DATE}.csv\"\n",
    "# INPUT_DIR=f\"./data/{DATE}/{DATASET}/{DATATYPE}/\"\n",
    "INPUT_DIR=\"./api_responses/datasets/\"\n",
    "OUTPUT_FILE_JSON=\"datasets_merged.json\"\n",
    "OUTPUT_FILE_CSV=\"datasets_merged.csv\"\n",
    "async def main():\n",
    "    all_json_files = glob.glob(f\"{INPUT_DIR}*.json\")\n",
    "    print(\"{} JSON files found.\".format(len(all_json_files)))\n",
    "    tasks=[read_json_file(file) for file in all_json_files]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    flattened_list = [item for sublist in results if sublist is not None for item in sublist]\n",
    "    json_dict={item['id']:item['name'] for item in flattened_list}\n",
    " \n",
    "    await write_json_file(OUTPUT_FILE_JSON, json_dict)\n",
    "    \n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1567\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_json(OUTPUT_FILE_JSON)\n",
    "# df.rename(columns={\"date\": \"date\", \"datatype\": \"datatype\", \"station\": \"station_id\", \"attributes\": \"attributes\", \"value\": \"value\"}, inplace=True)\n",
    "# df['dataset_name']=\"GSOM\"\n",
    "# sorted_columns = [\"dataset_name\",  \"station_id\",\"date\",\"datatype\",\"attributes\", \"value\"]\n",
    "# df = df[sorted_columns]\n",
    "df.head()\n",
    "print (len(df))\n",
    "# print (len(df))\n",
    "# df.drop_duplicates(subset=[\"station_id\",\"date\",\"datatype\"], keep=\"first\", inplace=True)\n",
    "# print (len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_FILE_CSV, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
